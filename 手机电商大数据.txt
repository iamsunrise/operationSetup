java -classpath /home/work/project/appEcommerce/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain > /tmp/test.log

ansible all -a "java -classpath log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain 1 1000> /tmp/test.log"

ansible all -m copy -a "src=log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar dest=/home/work/project/appEcommerce"

ansible all -a "java -classpath /home/work/project/appEcommerce/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain 1 1000> /tmp/test.log"

ansible all -a 'java -classpath /home/work/project/appEcommerce/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain  '


ansible all -a 'date -s 2019-09-02'
ansible all -a 'ntpdate -u ntp.api.bz'
ansible all -a 'date '



hadoop 
./hadoop-common-2.6.5.jar
./hadoop-hdfs-2.6.5.jar
./hadoop-auth-2.6.5.jar
./commons-configuration-1.6.jar
./commons-io-2.4.jar
./htrace-core-3.0.4.jar
拷贝到flume/lib下

ansible all -a "/usr/local/hadoop/sbin/start-all.sh start"
ansible all -a "/usr/local/hadoop/sbin/stop-all.sh stop"
ansible all -a "/usr/local/hadoop/sbin/start-dfs.sh"
ansible all -a "/usr/local/hadoop/sbin/stop-dfs.sh stop"
ansible all -a "jps"
ansible zookeeper -m shell -a "/usr/local/zookeeper/bin/zkServer.sh start"
ansible all -a "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties"
ansible all -a "/usr/local/kafka/bin/kafka-server-stop.sh /usr/local/kafka/config/server.properties"
ansible all -m shell -a "export JMX_PORT=9988 && /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties" 
ansible all -a "/usr/local/kafka/bin/kafka-server-stop.sh stop"
nohup /usr/local/kafka-manager/bin/kafka-manager   -Dhttp.port=7456 >/usr/local/kafka/start.log 2>&1 &
ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/yarn-site.xml dest=/usr/local/hadoop/etc/hadoop/"

ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/core-site.xml dest=/usr/local/hadoop/etc/hadoop/"
ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/hdfs-site.xml dest=/usr/local/hadoop/etc/hadoop/"
ansible flume -a "/usr/local/flume/bin/flume-ng agent --name a1 --conf-file /usr/local/flume/conf/file-flume-kafka.conf &"
生产
/usr/local/flume/bin/flume-ng agent --name a1 --conf-file /usr/local/flume/conf/file-flume-kafka.conf &
消费
/usr/local/flume/bin/flume-ng agent --name a1 --conf-file /usr/local/flume/conf/kafka-flume-hdfs.conf &
java -classpath /home/work/project/appEcommerce/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain>/tmp/bigdata/test.log
hadoop支持lzo
ansible all -m copy -a "src=/home/work/tools/hadoop-lzo-0.4.20.jar dest=/usr/local/hadoop/share/hadoop/common/"
ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/core-site.xml dest=/usr/local/hadoop/etc/hadoop/"




CREATE TABLE lzo (
ip STRING
)INPUTFORMAT"com.hadoop.mapred.DeprecatedLzoTextInputFormat"

OUTPUTFORMAT \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat";



CREATE TABLE lzo (
ip STRING,
user STRING,
time STRING,
request STRING,
status STRING,
size STRING,
rt STRING,
referer STRING,
agent STRING,
forwarded String
)
partitioned by (
date string,
host string
)
row format delimited
fields terminated by '\t'
STORED AS INPUTFORMAT "com.hadoop.mapred.DeprecatedLzoTextInputFormat"
OUTPUTFORMAT "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat";

load data inpath '/origin_data/gmall/log/topic_event/2019-12-09' into table gmall.ods_event_log partition(dt='2019-12-09');




insert overwrite table dwd_start_log
PARTITION (dt='2019-12-09')
select 
    get_json_object(line,'$.mid') mid_id,
    get_json_object(line,'$.uid') user_id,
    get_json_object(line,'$.vc') version_code,
    get_json_object(line,'$.vn') version_name,
    get_json_object(line,'$.l') lang,
    get_json_object(line,'$.sr') source,
    get_json_object(line,'$.os') os,
    get_json_object(line,'$.ar') area,
    get_json_object(line,'$.md') model,
    get_json_object(line,'$.ba') brand,
    get_json_object(line,'$.sv') sdk_version,
    get_json_object(line,'$.g') gmail,
    get_json_object(line,'$.hw') height_width,
    get_json_object(line,'$.t') app_time,
    get_json_object(line,'$.nw') network,
    get_json_object(line,'$.ln') lng,
    get_json_object(line,'$.la') lat,
    get_json_object(line,'$.entry') entry,
    get_json_object(line,'$.open_ad_type') open_ad_type,
    get_json_object(line,'$.action') action,
    get_json_object(line,'$.loading_time') loading_time,
    get_json_object(line,'$.detail') detail,
    get_json_object(line,'$.extend1') extend1
from ods_start_log 
where dt='2019-12-09';
