java -classpath log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain > /tmp/test.log

ansible all -a "java -classpath log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain 1 1000> /tmp/test.log"

ansible all -m copy -a "src=log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar dest=/home/work/project/appEcommerce"

ansible all -a "java -classpath /home/work/project/appEcommerce/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain 1 1000> /tmp/test.log"

ansible all -a 'java -classpath /home/work/project/appEcommerce/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain  '


ansible all -a 'date -s 2019-09-02'
ansible all -a 'ntpdate -u ntp.api.bz'
ansible all -a 'date '



hadoop 
./hadoop-common-2.6.5.jar
./hadoop-hdfs-2.6.5.jar
./hadoop-auth-2.6.5.jar
./commons-configuration-1.6.jar
./commons-io-2.4.jar
./htrace-core-3.0.4.jar
拷贝到flume/lib下

ansible all -a "/usr/local/hadoop/sbin/start-all.sh start"
ansible all -a "/usr/local/hadoop/sbin/stop-all.sh stop"
ansible all -a "/usr/local/hadoop/sbin/start-dfs.sh"
ansible all -a "/usr/local/hadoop/sbin/stop-dfs.sh stop"
ansible all -a "jps"
ansible zookeeper -m shell -a "/usr/local/zookeeper/bin/zkServer.sh start"
ansible all -a "/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/server.properties"
ansible all -a "/usr/local/kafka/bin/kafka-server-stop.sh /usr/local/kafka/config/server.properties"
ansible all -m shell -a "export JMX_PORT=9988 && /usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties" 
ansible all -a "/usr/local/kafka/bin/kafka-server-stop.sh stop"
nohup /usr/local/kafka-manager/bin/kafka-manager   -Dhttp.port=7456 >/usr/local/kafka/start.log 2>&1 &
ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/yarn-site.xml dest=/usr/local/hadoop/etc/hadoop/"

ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/core-site.xml dest=/usr/local/hadoop/etc/hadoop/"
ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/hdfs-site.xml dest=/usr/local/hadoop/etc/hadoop/"
ansible flume -a "/usr/local/flume/bin/flume-ng agent --name a1 --conf-file /usr/local/flume/conf/file-flume-kafka.conf &"
生产
/usr/local/flume/bin/flume-ng agent --name a1 --conf-file /usr/local/flume/conf/file-flume-kafka.conf &
消费
/usr/local/flume/bin/flume-ng agent --name a1 --conf-file /usr/local/flume/conf/kafka-flume-hdfs.conf &
java -classpath /home/work/project/appEcommerce/log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.atguigu.appclient.AppMain>/tmp/bigdata/test.log
hadoop支持lzo
ansible all -m copy -a "src=/home/work/tools/hadoop-lzo-0.4.20.jar dest=/usr/local/hadoop/share/hadoop/common/"
ansible all -m copy -a "src=/usr/local/hadoop/etc/hadoop/core-site.xml dest=/usr/local/hadoop/etc/hadoop/"




CREATE TABLE lzo (
ip STRING
)INPUTFORMAT"com.hadoop.mapred.DeprecatedLzoTextInputFormat"

OUTPUTFORMAT \"org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat";



CREATE TABLE lzo (
ip STRING,
user STRING,
time STRING,
request STRING,
status STRING,
size STRING,
rt STRING,
referer STRING,
agent STRING,
forwarded String
)
partitioned by (
date string,
host string
)
row format delimited
fields terminated by '\t'
STORED AS INPUTFORMAT "com.hadoop.mapred.DeprecatedLzoTextInputFormat"
OUTPUTFORMAT "org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat";

